# Advanced Python 3

## Printing to Debug

Use logpoints instead

Prints to the console and doesnt stop program

## Variables

### Iterable / sequence

string, list, tuple, ...

### Unused Variables

```python
_ = 5
first, _, last = ["first", "get rid of", "last"]  # will get rid of "get rid of"
```

### Get Address

Every object has a unique identifier

`id(a)`

### Global Variable

define a global variable in local scope with global keyword

```python
def spam():
    global eggs
    eggs = 'spam'
eggs = 'global'
spam()
print(eggs) #prints spam
```

### Garbage collection

When no variable points to an object of data the object is orphaned and there is no way to access it.

Python will eventually notice it's inaccessible and reclaim the allocated memory

## Special Operators

### yield

yield will return only when `__next__()` called on object

```python
for iterator in iterable[1:]:
    yield joiner
    yield from iterable
```

### * operator

depends what it is put on

#### variable assignment, argument

unpacking operator

- assigns a value from an iterable to a sequence of variables
  - if returning 1 value, just returns a value
  - else returning > 1 value, returns a list of values

```python
# unpack list
arr = [1,2,3]
print(*arr) #Output: 1 2 3 INSTEAD OF [1, 2, 3]
## same as ' '.join(map(str, arr))

# unpack iterable into multiple variables
first, *middle, last = [1, 2, 3, 5, 7] # first = 1, middle = [2,3,5] last = 7

# unpack iterable into single variable
*string, = 'PythonIsTheBest' #['P', 'y', 't', 'h', 'o', 'n', 'I', 's', 'T', 'h', 'e', 'B', 'e', 's', 't']
```

#### parameter

packing operator

- pack several values in a single tuple

```python
myFunc(1, "a")

def myFunc(*allParams):
  print(allParams) # (1,'a')
```

### ** unpacking operator for dictionaries

can use inside callables and other dictionaries

`merged_dict = {**food, **colors}`

## Loops

### Generators | Waits to be asked loop

sum(x**2 for x in range(5))

Like list comprehension but instead of looping through all at once 

it waits to be ask to do the *next* iteration

- Generates the next value on the fly rather than storing it all in memory
- Has a yield instead of return
- An instance of the generator can only be used once
    ```python
    myGenerator = createMyGenerator()  # myGenerator can only be used once
    """ """
    for v in createMyGenerator()  
    # createMyGenerator() creates a generator only for the scope of this for loop
    # can call the function again somewhere else
    ```
- Considered iterator (handles creating `__iter()__`)
```python
def createGenerator():
    myList = range(3)
    print("second")  # second
    for i in myList:
        yield i*i  # returns a generator
        print("test")  # prints after each print(i)
myGenerator = createGenerator()
for i in myGenerator:
    print(i)  # first
```

#### yield

returns a generator

yield makes it a function a generator

- When function is called no code is ran (prev, curr = 0,1 not ran when function called)
- waits for __next__ to be called on the generator object to start executing code
  - stops executing after yield ran
  - Order of execution:
    ```python
    #same as the class above
    def fib():
        prev, curr = 0,1
        while True:
            yield curr
            prev,curr = curr, prev + curr
    f = fib()
    list(islice(f, 0, 10)) #islice is an efficient split
    ```
    - f is idle, islice() is idle,
        list() will consume all of its arguments by
        calling next() on the islice() instance which will
        call next() on the f instance
    - yield curr produces value in curr and go idle again
    - islice will produce it because not past 10th value
    - list can add curr's value of 1
    - next iteration will pick up after yield until yield encountered again
    - repeats until list() asks islice() for the 11th value
    - islice() will raise a "StopIteration" exception
    - generator (f) will be garbage collected

```python
numbers = [1,2,3,4,5,6]
lazy_squares = (x * x for x in numbers)  
lazy_squares #<generator object <genexpr> at 0x10d1f5510>
next(lazy_squares) #1
list(lazy_squares) #[4,9,16,25,36]
return ", ".join(  #NO FUCKING CLUE WHAT THIS IS LOL
        f"{param}: {value}" #generator expression
        for param, value in attributes.items()
    )
```

### Generator Expression | Single Line Iterator Creation

Like list comprehension but `( )` instead of `[ ]`

Generator expressions are often used with functions like sum, max, and min
`sum(x**2 for x in range(5))`

```python
g = (x**2 for x in range(3))`

# Iterate
next(g)  # 0
for (v in g):
    print(v)  # 2, 4
next(g)  # StopIteration Error
```
- Hard example
    ```python
    numbers = [1,2,3,4,5,6]
    lazy_squares = (x * x for x in numbers)  
    lazy_squares #<generator object <genexpr> at 0x10d1f5510>
    next(lazy_squares) #1
    list(lazy_squares) #[4,9,16,25,36]
    return ", ".join(  #NO FUCKING CLUE WHAT THIS IS LOL
            f"{param}: {value}" #generator expression
            for param, value in attributes.items()
        )
    ```
- can never get the 1 again! Only can be used/iterated once
- Why use?:
  - Less memory, CPU, & lines of code
- When to use?:
  - Useful when you have a huge set of values you only need to read once
    ```python
    #Instead of this
    def something():
        result = []
        for ... in ...:
            result.append(x)
        return result
    #Do this
    def iter_something():
        for ... in ...:
            yield x
    something = list(iter_something()) #Only if you need a list structure
    ```
- print contents:
    `print(*(f"{s}" for s in ["bar", "test"]))`
  - * = unpacking operator (iterates(i.e. call __next__()) over iterable and assigns each value to a different variable)
    - "itertools" library assists a lot

## Collections

`from collections import`

like the built in containers but w/ added stuff

### defaultdict

- dict subclass that calls a factory function to supply missing values
- dict subclass
- doesnt give exception when trying ot access non-existent key (key error)
  - calls a factory function to supply missing values
```python
from collections import defaultdict
nums = defaultdict(int)
nums['one'] = 1
print(nums['two'])  # prints 0
```

### Namedtuple

Create a tuple with keys

- factory function for creating tuple subclasses with named fields
```python
from collections import namedtuple
Student = namedtuple('Student', 'fname, lname, age')
s1 = Student('Peter', 'James', '13')
print(s1.fname)
```
    
### deque

optimal version of lists

- fast appends and pops on either end

```python
from collections import deque
#initialization
list = ["a","b","c"]  
deq = deque(list)  
print(deq)
#insertion
deq.append("z")  
deq.appendleft("g")  
print(deq)
#removal
deq.pop()  
deq.popleft()  
print(deq)
```

### ChainMap

- dict-like class for creating a single view of multiple mappings
- combines a lot of dictionaries together and returns a list of dictionaries

**When to use?**
- search through multiple dictionaries at a time


```python
import collections
dictionary1 = { 'a' : 1, 'b' : 2 }  
dictionary2 = { 'c' : 3, 'b' : 4 }  
chain_Map = collections.ChainMap(dictionary1, dictionary2)  
print(chain_Map.maps)
```
    
### Counter

dict subclass for counting occurrences of each value present hashable objects

```python
from collections import Counter
list = [1,2,3,4,3]
answer = Counter()
answer = Counter(list)
print(answer[3]) #prints 2
```

### OrderedDict (not needed in Python 3.7)

- dict subclass that remembers the order entries were added
  - even if the value of the key is changed

```python
from collections import OrderedDict  
order = OrderedDict()  
order['a'] = 1  
order['b'] = 2  
order['c'] = 3  
print(order)
#unordered dictionary
unordered=dict()
unordered['a'] = 1  
unordered['b'] = 2  
unordered['c'] = 3 
print("Default dictionary", unordered)
```

### UserDict

- wrapper around dictionary objects for easier dict subclassing
    
### UserList

- wrapper around list objects for easier list subclassing
    
### UserString

- wrapper around string objects for easier string subclassing

## Iteration

```python
for x in myList:
    # ...
```

### Iterable vs Iterator

- Iterable = overall ds can iterated with `__iter__()` / has iterator 
- Iterator = object that produces the next value when you call its `__next()__` method

### Iterable

`myList` is the iterable, an object that has the iterator protocol `__iter__()`

- `__iter__()` returns an iterator
  - an object with `__next()__`
  - could just return self if self has `__next__()`
- ex. string, list, tuple, set, range(), file
- values stored in memory

### Iterator

Any object that has a `__next__()` method

1. Gets an iterator of `myList`
   1. Call `iter(myList)`
   2. Returns object with a `__next__()` method
2. Use the iterator to loop over items
   1. Keep calling `__next__()`
   2. which returns result into `x`
      - if a `StopIteration` is raised from within `__next__()`, it means there are no more values in the iterator and the loop is exited

### Iterable Functions

- Map | apply function to each element in list
  - `map(func, list)`
  - returns map object with results
  - convert to list `list(map(...))`
- Filter | applies function to each element of list that meets condition
  - `filter(func, list)`
  - returns filter object with elements that returned true
  - convert to list `list(filter(...))`
- Reduce | apply function to each pair of elements in list and return one value
    ```python
    from functools import reduce
    reduce(func, list)
    multiply=reduce(lambda a,b:a*b,seq)
    ```
- Zip | take 0 or more iterables and make an iterator of ith tuples
  - `zip(*iterables)`
  - and stops at the length of the shortest iterable
  - ex) iterable1[0] AND iterable2[0] stored in the 0th tuple
- All True?
  - `all(iterable)`
- Any True?
  - `any(iterable)`
  - Often used with generators on lists
    - `any(letter == 't' for letter in 'monty')  # True`
- Reverse Iterator
  - `reversed(seq)`
  - Prereqs
    - seq has a __reversed__()
    - OR
    - *Sequence Protocol* supported
  - __len__()
  - __getitem__()
  - w/ int args starting at 0
    - returns a reverse iterator

## Decorators

<https://stackoverflow.com/questions/5929107/decorators-with-parameters>
<https://www.google.com/search?client=firefox-b-1-d&q=decorator+with+arguments>
<https://www.geeksforgeeks.org/decorators-with-parameters-in-python/>
<https://www.youtube.com/watch?v=MjHpMCIvwsY>
  
- Allow you to change the behavior of a function 
  - without modifying the function
  - run the same code on multiple functions
    - add logging
    - test performance
    - perform caching
    - verify permissions
- How?: its a func that takes a func as a param and calls it in a nested function with code before and after the call potentially
    ```python
    def my_decorator_func(func):
        def wrapper_func(*args, **kwargs):
            # Do something before the function.
            func()
            # Do something after the function.
        return wrapper_func

    @my_decorator_func
    def execute_inside_wrapper():
        pass
    ```
- Example
    ```python
    @mydeco
    def add(a,b):
        return a+b
    
    add(2,2)
    # actually calling mydeco(add)
    ```
- Arguments get passed to the wrapper function inside the `@mydeco` function

#### Decorate every function of a class

This uses a metaclass to automatically decorate all methods of the class with before_every_method_decorator, which runs code before each method call. This approach is more advanced and alters the class creation process, so it's important to understand the implications and how metaclasses work in Python

```python
def before_every_method_decorator(method):
    def wrapper(*args, **kwargs):
        print("This runs before every method call.")
        return method(*args, **kwargs)
    return wrapper

class DecoratorMeta(type):
    def __new__(cls, name, bases, dct):
        new_dct = {}
        for attribute_name, attribute in dct.items():
            if callable(attribute):
                attribute = before_every_method_decorator(attribute)
            new_dct[attribute_name] = attribute
        return type.__new__(cls, name, bases, new_dct)

class MyClass(metaclass=DecoratorMeta):
    def method_one(self):
        print("Method one.")

    def method_two(self):
        print("Method two.")

obj = MyClass()
obj.method_one()
obj.method_two()
```

## Error Handling

```python
try:
    # Throw Exceptions
    if False:
        raise Exception("It's false")
    else if False && False:
        raise ValueError("Not proper value")
    # Catch Exceptions
    print(42/0)
    print("This will never print")
except ZeroDivisionError:  # catch
    print('cant divide by 0')
except:  # default
    print('Some error happened')
finally:  # always executes
    print('Always prints')

# ...

assert podBayDoorStatus == 'closed', 'The pod bay doors need to be closed.'
# AssertionError: The pod bay doors need to be closed.
```

- traceback errors 
  - `import traceback`

## Input

`myInput = input("Message to user: ")`

- Dynamic Input
  ```python
  catNames = []
  while True:
      name = input()
      catNames = catNames + [name]
      if name == "exit":
          break
  ```

## Context Managers

ensures that resources are returned after usage

### Using `With`

```python
with open("test.txt") as line:
    data = line.read()
# returns resources after with statement exits
```

### Creating from Scratch

- `__enter__()`
  - returns the resource that needs to be managed
- `__exit__()`
  - no return, performs cleanup

```python
class ContextManager():
    def __init__(self):
        print('init method called')
        
    def __enter__(self):
        print('enter method called')
        return self
    
    def __exit__(self, exc_type, exc_value, exc_traceback):
        print('exit method called')

with ContextManager() as manager:
    print('with statement block')
print("Last thing to be printed")
```

## Files

`import os`

### Handling files proper

```python
with open("test.txt") as line:
    data = line.read()
# OR
class FileManager():
    def __init__(self, filename, mode):
        self.filename = filename
        self.mode = mode
        self.file = None
        
    def __enter__(self):
        self.file = open(self.filename, self.mode)
        return self.file
    
    def __exit__(self, exc_type, exc_value, exc_traceback):
        self.file.close()
        
with FileManager('test.txt', 'w') as f: # loading a fil
    f.write('Test')

print(f.closed)
```

- Open/read/write/close file:
    ```python
    # Open
    myFile = open(path, mode = r)
    myContents = myFile.read()
    readlines() # list of string values from file
    myFile.close()

    # Write
    open(path, w) # overrides original file contents
    # creates a new file if it doesnt exist
    write('test') 

    # Close
    myFile.close()

    # Append
    open(path, a) # append to the end of the file
    ```
- copy,move,rename,delete:
    `import shutil`
- safe delete:
    `import send2trash`
- Join file path
    `os.path.join('usr', 'bin', 'spam')`
- File size:
    `os.path.getsize(path)`
- Directory
  - Get current working directory
    `os.getcwd()`
  - Change current working directory
    `os.chdir`
  - Get files in dir:
      `os.listdir(path)`
  - Check if it exists:
      `os.path.exists(path)`
  - Check file exists:
      `os.path.isfile(path)`
  - Check dir exists:
    `os.path.isdir(path)`

## Standard Library | stl

[Standard Library](https://docs.python.org/3/library/)

- Modules written in C to give access to the system Python doesnt have
  - standardized solutions to common problems in programming
  - enhance portability by abstracting away platform-specifics into platform-neutral APIS

### Command Line arguments

```python
import sys
sys.argv[1]
```

### Random

```python
import random, sys, os, math
random.randint(1,10)
# OR
from random import * #from random import everything
randint(1,10) #didnt need to specify random. because of from
sys.exit()

# GET HELP
help(randint)
```

## 3rd Party Libraries

- Install
  - Windows:
    1. In the python directory, under scripts folder
    2. ./pip.exe install pyperclip
    - OR
    1. `python -m pip install pyperclip # may require elevation`
  - macOS:
    - `python3 -m pip install pyperclip`
  - linux:
    - `apt-get install python3-tk`
    - `python3 -m pip install pyperclip`

### Copy & Paste

```python
import pyperclip
pyperclip.copy('test')
pyperclip.paste()
```

### Save variables to hard drive

```python
import shelve
myFile = shelve.open('mydata')
cats = ['sophie', 'pooka', 'Simon']
myFile['cats'] = cats
myFile.close()
```

### matplotlib

`import matplotlib.pyplot as plt`

- wont show on wsl

### pandas

working with large datasets

### numpy

`import numpy as np`

complex math and common statistical operations

### logging logs


### Asyncio | Concurrent Execution | Asynchronous I/O

[Distribute tasks via queues](https://docs.python.org/3/library/asyncio.html)

`import asyncio`
    
### Multiprocessing
    
[Process-based Parallelism](https://docs.python.org/3/library/multiprocessing.html)
    
`import multiprocessing`
    
- Spawns processes by 
  1. side-stepping the Global Interpreter Lock
     - *Global Interpreter Lock* assures CPython only has one thread execute Python bytecode
  2. using subprocesses instead of threads
        
- When to use:
  - for CPU heavy processes that dont benefit from threading
  - Programs that need more CPU

- How to:
  - create a process
    - `from multiprocessing import Process`
  - offer a convenient means of parallelizing the execution of a function across multiple input values
    - `from multiprocessing import Pool`
  - Threading
    - a thread is an execution context (all the info needed to execute / resume executing a stream of instructions)
    - two things appearing to be happening at once
      - but threads dont run at the same time
      - even if they are on different processors
    - When to use?:
      - Tasks that spend much of their time waiting for external events
      - NOT for CPU-bound problem
        - NOT for processes that require heavy CPU computation and spend little time waiting for external events might not run faster at all.
      - Want tasks to run simultaneously and not have to wait on each other i.e. CONCURRENCY
      - takes far less time to create & terminate a thread than to create a new processes
      - can share common data, they do not need to use inter-process communication
      - slower than context switching
    - Example:
        A web browser will need multiple threads
        1) Display the page
        2) Download files
        ...
        If you only had one thread, the web page could not display while the download is happening 
    - multiprocessing vs threading
      - A program running is called a process
      - A program can have multiple processes
      - A process can have multiple threads
    - Process vs Thread:
      - A process has data
      - A thread has a stack, registers, and the program counter
    - Subprocess
      - run & control other programs

## Security Considerations

[More info](https://docs.python.org/3/library/security_warnings.html)

- base64, cgi, hashlib, http.server, logging, multiprocessing, pickle
  random, shelve, ssl, subprocess, tempfile, xml, zipfile

## Virtual Environment
    
- Windows:
  1) `py -3 -m venv .venv`
  2) `.venv\scripts\activate`
  3) if "Activate.ps1...", change PowerShell execution policy to allow scripts to run
      1) Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
- macOS/Linux:
  1) `python3 -m venv .venv`
  2) `source .venv/bin/activate`
- VSCode
  - Prompted when a new virtual environment created:
    - "Set as default for your workspace folder?"
    - If yes, Environment automatically activated when you open a new terminal
  - **Set environment as python interpreter**

### Commands

- deactivate
    `$ deactivate`

## CPython

Python is compiled into instructions (bytecode), then it's ran on a virtual machine 

- Types are represented by a struct called PyObject which every object in Python uses
  - Contains 2 attributes
    1. ob_refcnt (reference count)
    2. ob_type (pointer to another type)